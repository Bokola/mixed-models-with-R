# Common Extensions



## Additional Grouping Structure


### Cross-classified models

Oftentimes there will be additional sources of variance beyond one grouping factor. Consider as an example, a visual perception experiment where there are multiple trials for each individual along with specific images displayed.  Such data might look like this.

```{r demodata_crossed, echo=FALSE}
crossing(Person=1:20, Image=letters[1:10]) %>% 
  mutate(score=sample(1:10, 200, replace=T)) %>% 
  DT::datatable(options=list(dom='tp', autoWidth=F, 
                             columnDefs=list(
                               list(width='10px', targets=0:2),
                               list(className = 'dt-center', targets = 0:2))), rownames = F, width=250)
```

<br>
<br>

In such a case we have observations clustered within both person and image, but person and image are not nested within one another. For example all participants see all 10 items.  Such a situation is typically referred to as one in which there are <span class="emph">crossed</span> random effects.  In such settings we have multiple sources variances to consider.


#### Example: Student achievement

For our own demonstration we'll look at achievement scores for students.  The sources of dependency are due to students having gone to the same primary or secondary schools.  However, in this example, going to a primary school doesn't necessarily mean you'll go to a specific secondary school.  Note also that there are no repeated measures, we see each student only one. Here's a quick look a the data, and for more detail, check the [appendix][Data].


```{r pupil_nurses_setup, echo=FALSE, eval=FALSE}
pupils = read_sav('data/joop_hox_data2/9 CrossClass/pupcross.sav') %>% 
  as_factor() %>% 
  mutate(ACHIEV = as.numeric(as.character(ACHIEV)),
         PUPSEX = factor(PUPSEX, labels=c('male', 'female')) ) %>% 
  rename(achievement = ACHIEV,
         primary_school_id = PSCHOOL,
         secondary_school_id = SSCHOOL,
         sex = PUPSEX,
         ses = PUPSES,
         primary_denominational=PDENOM,
         secondary_denominational=SDENOM)  
save(pupils, file='data/pupils.RData')

nurses = read_sav('data/joop_hox_data2/2 Basic Model/nurses.sav') %>% 
  as_factor() %>% 
  rename(experience = experien,
         treatment = expcon) %>% 
  mutate(treatment = factor(treatment, labels=c('Ctrl', 'Training'))) %>% 
  mutate(age = as.numeric(as.character(age)))
save(nurses, file='data/nurses.RData')
```


```{r examine_pupil_data, echo=1}
load('data/pupils.RData')
DT::datatable(pupils, 
              options=list(dom='tp', 
                           scrollX=T,  
                           autoWidth=T),
                           # columnDefs = list(list(width = '150px', targets = 1),
                           #                   list(width = '100px', targets = 3))), 
              rownames=F)
```
<br>
<br>

For our mixed model we'll look at the effects for `sex` and socioeconomic status, `ses`, a six level variable from low to high on scholastic achievement.  The range of achievement scores is roughly `r round(min(pupils$achievement))` to `r round(max(pupils$achievement))`, with mean of `r round(mean(pupils$achievement), 1)` and standard deviation `r round(sd(pupils$achievement), 1)`.  We'll take into account the clustering at primary school and secondary school.  To incorporate the additional structure in <span class="pack">lme4</span> syntax is very easy, we just do as we did before[^crossed_notation].

```{r cross_classified, eval=1}
pupils_crossed = lmer(achievement ~ sex + ses 
                      + (1|primary_school_id) + (1|secondary_school_id), 
                      data = pupils)
summary(pupils_crossed, correlation=F)
```


```{r cross_classified_fixed, echo=FALSE}
pander(tidy(pupils_crossed, 'fixed', conf.int=T) %>% mutate_if(is.numeric, arm::fround, digits=2))
```

The fixed effects tell us there is a positive effect of being female on achievement, and in general, relative to lowest SES category, being in the upper categories of SES also has a positive effect.

```{r  cross_classified_random, echo=FALSE}
# note tidy doesn't work with multiple random effects and conf.int
crossed_var_cor = tidy(VarCorr(pupils_crossed)) %>% 
  select(-var2) %>% 
  rename(variance=vcov, sd=sdcor)
crossed_var_cor %>%  
  mutate_if(is.numeric, arm::fround, digits=2) %>% 
  mutate_all(function(x) ifelse(is.na(x), '', x)) %>%
  pander()

```

When we look at the variance components we see that primary and secondary school does contribute about `r round(sum(crossed_var_cor$variance[1:2])/sum(crossed_var_cor$variance)*100)`% of the total variance.  Most of the variance attributable to school comes from the primary school.

Note that we have the usual extensions here if desired.  As an example, we could also do random slopes for student level characteristics.



### Hierarchical Structure

Now that we have looked at cross-classified models, we can examine hierarchical cluster structuring.  In this situation we have clusters nested within other clusters, which may be nested within still other clusters.  A typical example might be cities, within counties, within states.

#### Example: Nurses and Stress

For our demonstration we'll use the nurses data set. Here we are interested in the effect of a training program (`treatment`) on stress levels (on a scale of 1-7) of nurses.  In this scenario, nurses are nested within wards, which themselves are nested within hospitals, so we will have random effects pertaining to ward (within hospital) and hospital. For more information see the [appendix][Data].

```{r nurses_data, echo=1}
load('data/nurses.RData')
DT::datatable(nurses, 
              options=list(dom='tp', 
                           scrollX=T,  
                           autoWidth=T),
                           # columnDefs = list(list(width = '150px', targets = 1),
                           #                   list(width = '100px', targets = 3))), 
              rownames=F)
```

<br>
<br>

For the model we examine effects of the treatment as well as several other covariates, at least one at each of the nurse, ward, and hospital levels. Again, when it comes to the fixed effects portion, you can simply think about that part as you would any standard regression, we just add covariates as theory/exploration would suggest.  To incoprate this type of random effects structure is not too different from the cross-classified approach, but does add a slight change.

```{r hierarchical, eval=1}
nurses_hierarchical = lmer(stress ~ age  + gender + experience 
                           + treatment + wardtype + hospsize 
                           + (1|hospital) + (1|hospital:wardid), data = nurses)
nurses_hierarchical = lmer(stress ~ age  + gender + experience 
                           + treatment + wardtype + hospsize 
                           + (1|hospital/wardid), data = nurses) # same thing!
summary(nurses_hierarchical, correlation=F)
```

```{r hierarchical_fixed, echo=FALSE}
tidy(nurses_hierarchical, 'fixed', conf.int=T) %>% 
         mutate_if(is.numeric, arm::fround, digits=2) %>% 
  pander(justify='lrrrrr')
```

As far as the fixed effects go, about the only thing that doesn't have a statistical effect is ward type.


```{r hierarchical_random, echo=FALSE}
# note tidy doesn't work with multiple random effects and conf.int
hierarch_var_cor = tidy(VarCorr(nurses_hierarchical)) %>% 
  select(-var2) %>% 
  rename(variance=vcov, sd=sdcor)
hierarch_var_cor %>%  
  mutate_if(is.numeric, arm::fround, digits=3) %>% 
  mutate_all(function(x) ifelse(is.na(x), '', x)) %>%
  pander(justify='lcrr')
```


### Crossed vs. Nested

The following shows the difference in the results from treating ward as nested vs. crossed. Notice anything different?

```{r crossed_vs_nested, echo=1:2}
nurses_hierarchical = lmer(stress ~ age  + gender + experience 
                           + treatment + wardtype + hospsize 
                           + (1|hospital) + (1|hospital:wardid), data = nurses)
nurses_crossed = lmer(stress ~ age  + gender + experience 
                           + treatment + wardtype + hospsize 
                           + (1|hospital) + (1|wardid), data = nurses)
hierarch_var_cor %>%  
  mutate_if(is.numeric, arm::fround, digits=3) %>% 
  mutate_all(function(x) ifelse(is.na(x), '', x)) %>%
  pander(justify='lcrr')

crossed_var_cor = tidy(VarCorr(nurses_crossed)) %>% 
  select(-var2) %>%
  rename(variance=vcov, sd=sdcor)
crossed_var_cor %>%  
  mutate_if(is.numeric, arm::fround, digits=3) %>% 
  mutate_all(function(x) ifelse(is.na(x), '', x)) %>%
  pander(justify='lcrr')
```


No? Good, you're not crazy.  Here's a quote from the [lme4 text](http://lme4.r-forge.r-project.org/book/Ch2.pdf), section 2.2.1.1, which is definitely worth your time.

> The blurring of mixed-effects models with the concept of multiple,
hierarchical levels of variation results in an unwarranted emphasis on 'levels'
when defining a model and leads to considerable confusion. It is perfectly
legitimate to define models having random effects associated with non-nested
factors. The reasons for the emphasis on defining random effects with respect to
nested factors only are that such cases do occur frequently in practice and that
some of the computational methods for estimating the parameters in the models
can only be easily applied to nested factors. 
>
This is not the case for the methods used in the lme4 package. Indeed there is
nothing special done for models with random effects for nested factors. When
random effects are associated with multiple factors exactly the same
computational methods are used whether the factors form a nested sequence or are
partially crossed or are completely crossed.

So there you have it.  When it comes to <span class="pack">lme4</span>, crossed vs. nested is simply a state of mind.


## Correlational Structure

Sometimes we will want to estimate the residual correlation structure. This especially the case in the longitudinal setting, where we think that observations closer in time would be more strongly correlated than those further apart.  

For reasons that defy my ability to parse, <span class="pack">lme4</span> does not provide the ability to do this, though practically every other mixed model package does[^lmerho].  In fact, two packages that come with the basic R installation do so, <span class="pack">mgcv</span> and <span class="pack">nlme</span>.  We'll demonstrate with the latter.

The following shows the same model we did before, but also includes an <span class="emph">autocorrelation</span> structure, of lag order one, for the residuals.  What this means is that we assume the residuals at one time point apart correlate with some value $\phi$, observations at two time points apart correlate $\phi^2$, and so on.  As such we only need to estimate $\phi$, while the rest are then automatically determined.  In <span class="pack">nlme</span> we use the built in <span class="func">corAR1</span> function and `correlation` argument.  Note also the different random effect specification (though not *too* different).

```{r corr_residual, echo=1:3, eval=-3}
library(nlme)
corr_res = lme(gpa ~ occasion, data = gpa,
               random = ~1|student, 
               correlation = corAR1(form = ~occasion))
summary(corr_res)
pander(corr_res, round=3)

vc = VarCorr(corr_res) # christ lme objects are the worst
cbind(rownames(vc), vc[,1:2]) %>% 
  data.frame(stringsAsFactors=F) %>% 
  mutate_at(vars(Variance, StdDev), function(x) round(as.numeric(x), 3)) %>% 
  rename(' ' = V1) %>% 
  pander
```

Notice first that the fixed effect for occasion is the same as [before][Mixed model]. The variance estimates have changed slightly along with the variances of the fixed effects (i.e. the standard errors). The main thing is that we have a new parameter `Phi`, that represents our autocorrelation, with value of `r round(coef(corr_res$model$corStruct, unconstrained = F), 3)`. This suggests at least some correlation exists among the residuals for observations next to each other in time, though it diminishes quickly as observations grow further apart.


## Generalized Linear Mixed Models


## Exercises

[^lmerho]: While I'm extremely grateful to the work put forth by those involved with lme4, making it probably the best mixed model package out there, this feature request has been made by its users for over a decade.  

[^crossed_notation]: I don't show the formal model here as we did before, but this is why depicting mixed models solely as 'multilevel' becomes a bit problematic in my opinion. In the standard mixed model notation it's straightforward though, you just add an addition random effect term, just as we do in the actual model syntax.
